{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DATA24HEL_DBT25/Databastyper\n",
        "# Kunskapskontroll 2\n",
        "\n",
        "Gör kurserna i den här samlingen: [https://learn.microsoft.com/en-us/collections/3140s6twkorq6z?&sharingId=A70F2DF98827F6CC](https://learn.microsoft.com/en-us/collections/3140s6twkorq6z?&sharingId=A70F2DF98827F6CC)\n",
        "\n",
        "### OBS! Du behöver __inte__ göra *exercises*!\n",
        "\n",
        "Svara på frågorna nedan. Eftersom kurserna är på engelska har jag skrivit även frågorna på engelska. Det går bra att svara på svenska eller engelska.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Microsoft Azure Data Fundamentals: Explore core data concepts\n",
        "### Explore core data concepts\n",
        "#### Identify data formats\n",
        "\n",
        "❓ What data format is often represented as JSON?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: JSON (JavaScript Object Notation) is a lightweight and human-readable format used to store and exchange semi-structured data. JSON is widely used in web applications, APIs, and NoSQL databases because of its flexibility in handling dynamic data structures. JSON parsers are widely used as its easy to breakdown the JSON formats using open source libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What data format is represented in a tabular format?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Structured data is typically stored in a tabular format, meaning it is organized into tables with rows and columns. This format is commonly used in relational databases such as Microsoft SQL Server, MySQL, and PostgreSQL,as well as in CSV (Comma-Separated Values) files. Each row represents a record, and each column defines an attribute of that record."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the data format of images, pdf-documents and binary files called?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Images, PDF documents, and binary files are considered unstructured data. These types of data do not follow a predefined format and are often stored as Binary Large Objects (BLOBs) in databases or object storage systems like Azure Blob Storage. Specialized techniques are required to process, retrieve, and analyze unstructured data efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Explore file storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Give an example of an optimized file format for structured and semi-structured data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Optimized file formats such as Apache Parquet and Avro are widely used for storing structured and semi-structured data efficiently.\n",
        "Parquet is a columnar storage format designed for fast query performance in big data analytics. It compresses data efficiently and is commonly used in Azure Data Lake Storage and Azure Synapse Analytics.\n",
        "Avro is a row-based storage format that supports schema evolution, making it suitable for data exchange and streaming data processing in tools like Azure Data Factory which is commonly used in Hadoop-based data processing.\n",
        "These formats help improve performance in analytical workloads by reducing storage space and increasing read efficiency.\n",
        "JSON format is a good example of storing semi-structured data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Explore transactional data processing\n",
        "❓ What are OLTP systems designed for?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: OLTP (Online Transaction Processing) systems are designed to handle real-time, high-volume transactional data with a focus on fast and efficient CRUD (Create, Read, Update, Delete) operations. They ensure data consistency and integrity through ACID (Atomicity, Consistency, Isolation, Durability) properties. OLTP systems are commonly used in applications such as banking, e-commerce, and inventory management, where quick transaction execution is essential.OLTP systems are commonly used to support real-time applications that handle business data, often known as line-of-business (LOB) applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Explore analytical data processing\n",
        "❓ What are OLAP systems designed for?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: OLAP (Online Analytical Processing) systems are built for complex data analysis, business intelligence, and reporting. These systems store historical data and allow users to perform multidimensional queries, aggregations, and trend analysis. OLAP systems are optimized for read-heavy workloads and are commonly used in data warehouses like Azure Synapse Analytics. They help businesses gain insights from large datasets, enabling better decision-making and strategic planning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore data roles and services\n",
        "#### Explore job roles in the world of data\n",
        "\n",
        "❓Describe some of the responsibilities of a:\n",
        "\n",
        "* Database Administrator\n",
        "* Data Engineer\n",
        "* Data Analyst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Database Administrator (DBA):\n",
        "\n",
        ". Manages and maintains database systems.\n",
        ". Ensures data integrity, security, and performance.\n",
        ". Handles database backups, recovery, and optimization.\n",
        ". Monitors and troubleshoots database issues to prevent failures.\n",
        "\n",
        "✔️ Data Engineer:\n",
        "\n",
        ". Designs and implements data pipelines for data ingestion, transformation, and storage.\n",
        ". Works with large datasets and optimizes data workflows.\n",
        ". Uses tools like Azure Data Factory, Apache Spark, and Databricks.\n",
        ". Ensures that structured and unstructured data is available for analysis.\n",
        "\n",
        "✔️ Data Analyst:\n",
        "\n",
        ". Analyzes and interprets data for business insights.\n",
        ". Collects, cleans, and analyzes data to generate insights.\n",
        ". Uses tools like Power BI to visualize data.\n",
        ". Uses SQL to extract and manipulate data.\n",
        ". Microsoft Azure Data Fundamentals: Explore relational data in Azure\n",
        ". Explore fundamental relational data concepts\n",
        ". Creates dashboards and reports to help organizations make data-driven decisions.\n",
        ". Identifies trends and patterns to support business strategy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Microsoft Azure Data Fundamentals: Explore relational data in Azure\n",
        "### Explore fundamental relational data concepts\n",
        "\n",
        "❓ How is relational data commonly organized?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Relational data is typically organized into tables, where each table represents a distinct entity or object. Each table consists of rows (also known as records or tuples), and columns (also known as attributes), where each column contains a specific type of data. To link tables together, relational databases use primary keys and foreign keys. A primary key uniquely identifies each row in a table, while a foreign key in one table points to a primary key in another table, creating a relationship between them. This structure helps avoid redundancy and ensures data integrity.\n",
        "\n",
        "For example, in an e-commerce application:\n",
        "\n",
        "The Customers table stores customer details (e.g., name, address).\n",
        "The Orders table stores information about customer orders.\n",
        "The Customer ID in the Orders table is a foreign key that links each order to a customer in the Customers table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What are the main reasons for normalizing relational data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Normalization is the process of organizing data in a way that minimizes redundancy and maintains consistency. The main reasons for normalizing relational data include:\n",
        "\n",
        "Reducing Data Redundancy: By eliminating duplicate data across tables, normalization prevents unnecessary storage and the risks of inconsistency.\n",
        "Ensuring Data Consistency: It ensures that data remains accurate and consistent across the database. When information needs to be updated (e.g., a customer’s address), it only needs to be updated once, avoiding conflicts.\n",
        "Improving Query Efficiency: By structuring data logically and eliminating repetition, normalization makes it easier and more efficient to run queries, improving database performance.\n",
        "Normalization also enforces referential integrity by ensuring that relationships between tables remain valid and accurate, helping to preserve data accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore relational database services in Azure\n",
        "\n",
        "❓ Which of the Azure SQL services requires you to manage configuration, backups, and other maintenance tasks yourself?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Azure SQL Managed Instance requires you to manage configuration, backups, and other maintenance tasks yourself.\n",
        "\n",
        "Azure SQL Managed Instance is a fully-managed database service that provides control over the configuration and management of the SQL instance, similar to a traditional on-premises SQL Server. Although many administrative tasks like backups, updates, and patching are automated, you still retain control over configurations, and certain aspects of management like backups and security."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Microsoft Azure Data Fundamentals: Explore non-relational data in Azure\n",
        "### Explore Azure blob storage\n",
        "\n",
        "❓ What are the three types of blob that Azure Blob Storage supports?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:Azure Blob Storage supports three types of blobs:\n",
        "\n",
        ". Block Blobs: Optimized for storing large amounts of unstructured data, such as images, videos, and backups. Block blobs are made up of individual blocks, each of which can be uploaded and managed separately. They are best suited for data that changes infrequently.\n",
        "\n",
        ". Append Blobs: Designed specifically for scenarios where data is frequently appended, such as logging. New data can only be added to the end of an append blob, and existing data cannot be modified or deleted.\n",
        "\n",
        ". Page Blobs: Used for applications that require random read/write access, such as virtual machine disks. Page blobs are organized into 512-byte pages and are optimized for fast, random updates to specific sections of the blob.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore fundamentals of Azure Cosmos DB\n",
        "#### Describe Azure Cosmos DB\n",
        "\n",
        "❓ Which data storage scenarios are Azure Cosmos DB suitable for? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Azure Cosmos DB is suitable for scenarios that demand high availability, low-latency, and scalable storage across geographically distributed applications. It is particularly useful in the following cases:\n",
        "\n",
        "Globally Distributed Applications: Cosmos DB is built for applications that need to be distributed across multiple geographic locations with seamless data replication to ensure high availability and disaster recovery.\n",
        "\n",
        "Real-Time Analytics: It can handle workloads that require real-time insights into data across many different regions, supporting both transactional and analytical workloads with minimal latency.\n",
        "\n",
        "Multi-Model Data: It supports a wide range of data models, including document, key-value, graph, and column-family data, making it versatile for a variety of application needs, whether for customer management systems, e-commerce, IoT, or gaming.\n",
        "\n",
        "Scalable and Flexible: It is designed to scale efficiently and can handle both large amounts of data and high transaction volumes, making it suitable for big data and IoT scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Identify Azure Cosmos DB API\n",
        "\n",
        "❓ With Azure Cosmos DB for NoSQL you can use SQL syntax to make queries to a NoSQL database, but how are the results formatted?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Azure Cosmos DB returns query results in JSON format. This allows for easy integration with applications and APIs that need to process structured, semi-structured, and hierarchical data. JSON is highly flexible, supporting nested objects and arrays, making it suitable for NoSQL databases like Cosmos DB, which often store complex data structures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Explore fundamentals of large-scale analytics\n",
        "### Explore analytical data stores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "❓ What kind of analytical data store should you choose when you have structured data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: When working with structured data, a data warehouse is the best choice such as Azure Synapse Analytics is recommended. A data warehouse stores and organizes structured data in a relational schema, which is optimized for analytical queries, reporting, and business intelligence. It allows for efficient aggregation and querying of data, which is essential for generating reports, dashboards, and performing other analytical tasks. These systems are designed to work with transactional data that is structured in tables.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of analytical data store should you choose when you have a mix of structured, semi-structured and unstructured data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: A data lake is the ideal solution when dealing with a mix of structured, semi-structured, and unstructured data. Data lakes allow organizations to store raw data in various formats without enforcing a specific schema at the time of ingestion, using a schema-on-read approach. This flexibility makes data lakes perfect for big data scenarios, where you need to store diverse data types (like logs, sensor data, and multimedia) and process them using distributed processing tools like Apache Spark and Azure Synapse.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is a hybrid data store that combines features of data lakes and data warehouses called?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: A data lakehouse is a hybrid architecture that combines the best features of both data lakes and data warehouses. It enables you to store raw, unstructured data in a data lake while also providing structured query capabilities and schema enforcement typically found in data warehouses. This architecture supports both big data processing and traditional analytical workloads, offering the scalability of a data lake and the relational querying features of a data warehouse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Store Data in Azure\n",
        "### Choose a data storage apporach in Azure\n",
        "#### Classify your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ How is business data classified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Business data is typically classified as structured data. It is highly organized and stored in relational databases with predefined schemas, making it easy to manage, query, and analyze. Structured data is well-suited for complex queries, particularly in business analytics, where the consistency and integrity of data are crucial. This type of data is usually historical and read-only, used mainly for reporting or analysis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "❓ How is data for a product catalog classified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Product catalog data is classified as semi-structured data. Although some parts of the data, like product names, prices, and IDs, are structured, other attributes such as product descriptions, specifications, and categories can vary significantly across different products. This flexible structure allows the catalog to evolve over time as new attributes are added, making semi-structured data an ideal classification for product catalogs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ How is data representing photos and videos classified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Photos and videos are classified as unstructured data because they do not adhere to a predefined schema or format. These files—whether images, videos, or audio—are stored as objects and lack the structure required for traditional relational databases. Unstructured data is typically stored in object storage solutions, such as Azure Blob Storage, where they can be easily accessed and retrieved.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Group multiple operations in a transaction\n",
        "\n",
        "❓ What is ACID?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: ACID is an acronym that stands for Atomicity, Consistency, Isolation, and Durability. These principles ensure that database transactions are processed reliably and maintain data integrity:\n",
        "\n",
        ". Atomicity ensures that all operations in a transaction are completed successfully or, if any part fails, the entire transaction is rolled back.\n",
        ". Consistency guarantees that a transaction brings the database from one valid state to another, ensuring data integrity.\n",
        ". Isolation means that the operations in a transaction are independent of others, preventing interference between concurrent transactions.\n",
        ". Durability ensures that once a transaction is committed, its effects are permanent, even in the event of a system failure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which of the three datasets (product catalog, photos and videos, business data) is transactional?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Business data is transactional. It typically involves operations such as updates, deletions, and additions that need to maintain consistency and integrity, such as in order processing, inventory management, or financial transactions. These operations require strict adherence to ACID properties to ensure the reliability and accuracy of the data.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose a storage solution in Azure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the recommended service for a semi-structured dataset that needs a high number of both read and write operations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Azure Cosmos DB is the recommended service for semi-structured datasets requiring high-frequency read and write operations. It supports NoSQL databases, offering flexibility for semi-structured data like JSON, and it provides low-latency, high-throughput performance, making it ideal for real-time applications. Cosmos DB also offers strong consistency and ACID support for transactions, ensuring reliable data management. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the recommended service for a structured dataset that will be used for analytical purposes only?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Azure SQL Database is recommended for structured datasets that are used purely for analytical purposes. It provides powerful relational database capabilities, supporting complex queries and analytics with ease. For more advanced analytical needs, Azure Synapse Analytics can be used in conjunction with Azure SQL Database for large-scale data processing and analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an Azure Storage Account\n",
        "#### Decide how many storage accounts you need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the difference between Hot and Cold access tiers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \n",
        ". The Hot access tier is optimized for data that is accessed frequently. It offers low-latency and high availability, but at a higher storage cost. This tier is ideal for data that requires real-time access, such as active content and user data.\n",
        "\n",
        ". The Cold access tier is designed for data that is rarely accessed. It provides lower storage costs, but higher access costs when retrieving data. This tier is well-suited for long-term backup, archival storage, or infrequently accessed records.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose your account settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ When creating an Azure Storage Account, which deployment model should you choose?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: The Resource Manager (ARM) deployment model is the preferred choice for creating an Azure Storage Account. It provides a more modern, flexible, and feature-rich experience compared to the Classic model. ARM allows for better resource management, supports automation, and offers role-based access control (RBAC), which enhances security and access management.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose an account creation tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ The most commonly used account creation tool is the Azure Portal. Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: The Azure Portal is the most commonly used tool for creating and managing Azure Storage accounts due to its user-friendly graphical interface. It simplifies the account creation process by guiding users through the configuration steps, making it accessible even for non-technical users. Additionally, it allows for real-time monitoring and management of resources with minimal effort.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Secure your Azure Storage account\n",
        "#### Explore Azure Storage security features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ How do you disable encryption at rest?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Encryption at rest is enabled by default in Azure Storage for security purposes and cannot be fully disabled. However, users can control encryption settings and manage encryption keys via Azure Key Vault. Disabling encryption at rest is generally not recommended, as it exposes your data to potential security risks.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What happens if you require *secure transfer* for your storage account?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: If we require secure transfer for your storage account, all communication with the account will be encrypted using HTTPS. This ensures that data is transmitted securely over the network, protecting it from interception or tampering during transmission.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is CORS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: CORS (Cross-Origin Resource Sharing) is a security feature that allows Azure Storage to accept requests from different domains, enabling web applications hosted on separate domains to access resources stored in Azure. It ensures that only authorized domains are allowed to make requests, protecting the storage resources from unauthorized access.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which Azure service can you use to audit accesses to your data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: To audit access to data in our storage account, we can use Azure Monitor and Azure Storage Analytics. These services track access logs and monitor activity in your storage account, helping us to  detect unauthorized access attempts, analyze usage patterns, and ensure compliance with security policies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Understand storage account keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which authentication option is the best for Blob and Queue storage?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:  The best authentication option for Blob and Queue storage is Azure Active Directory (Azure AD). Azure AD provides role-based access control (RBAC) and eliminates the need to manage storage account keys. This enhances security by ensuring that only authorized users and applications can access the storage resources.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Understand shared access signatures (SAS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What are the two levels of SAS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: here are two levels of Shared Access Signatures (SAS):\n",
        "\n",
        "1. Service-Level SAS: Grants restricted access to specific services like Blob, Queue, Table, and File within a storage account.\n",
        "2. Account-Level SAS: Provides broader permissions across all services within a storage account, including the ability to access containers, files, and queues.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Control network access to your storage account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What must you do before you change the default network access action from *grant* to *deny*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Before changing the default network access action from grant to deny,we must first configure valid network rules or set up a Virtual Network (VNet) to ensure that only authorized users and services can access the storage account. Otherwise, we may lock yourself out of the account.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store application data with Azure Blob Storage\n",
        "#### What are blobs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of data can't be stored as a blob?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Structured data, such as data typically stored in relational databases (e.g., tables with rows and columns), cannot be stored as blobs because blobs store unstructured or semi-structured data. Instead, this data should be placed in databases like Azure SQL Database, where it can be properly indexed and queried.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of data shouldn't be stored as a blob?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Data that requires frequent updates or complex querying and indexing, such as highly transactional data, should not be stored as blobs. Blob storage is ideal for unstructured or semi-structured data, such as images, videos, or logs, while structured data should be stored in a database like Azure SQL Database or Azure Cosmos DB.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Integrate data with Azure Data Factory or Azure Synapse Pipeline\n",
        "### Understand Azure Data Factory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which part of the symphony orchestra does Azure Data Factory play, according to the analogy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Azure Data Factory acts as the conductor in a symphony orchestra, coordinating the movement of data from various sources to destinations while ensuring smooth transformation and orchestration.In this analogy, the conductor doesn’t create the music but coordinates the performance, ensuring all musicians (data sources, transformations, destinations) play in harmony. Similarly, Azure Data Factory orchestrates and manages the movement, transformation, and integration of data from various sources, ensuring that each part of the data pipeline works together effectively to achieve the final result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Describe data integration patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What does ETL stand for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:  ETL stands for Extract, Transform, Load. This is a traditional data integration process where data is first extracted from various source systems, then transformed into a required format or structure, and finally loaded into a destination system or data warehouse for analysis or reporting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What does ELT stand for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: ELT stands for Extract, Load, Transform. In contrast to ETL, the ELT process extracts data from source systems, loads it directly into the destination (such as a data warehouse), and only then applies the necessary transformations to the data after it has been loaded. This approach is often used when the destination system has the processing power to handle transformations effectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the difference between ETL and ELT?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: The main difference between ETL and ELT lies in the order of operations and where the transformations occur:\n",
        "\n",
        ". ETL: Data is first extracted from the source, transformed (cleaned, formatted, or otherwise processed), and then loaded into the target system. ETL is typically used when the data destination (e.g., a database or data warehouse) does not have the necessary processing power to perform transformations.\n",
        "\n",
        ". ELT: Data is extracted and loaded directly into the destination first, and transformations are applied afterward. This method takes advantage of the target system’s processing capabilities to handle transformations, which is commonly used when the destination system (e.g., a cloud-based data warehouse like Azure Synapse) is powerful enough to process large-scale transformations.\n",
        "\n",
        "ETL processes data before loading into storage, while ELT loads raw data first and applies transformations afterward. ELT is more suited for large-scale analytics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create Data Factory activities and pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which are the three categories of Azure Data factory activities?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:\n",
        " 1. Data Movement Activities:\n",
        "These activities are responsible for moving data from one location to another, including data stores in both public and private networks. The Copy Activity is a prime example of a data movement activity, used to copy data between different data stores across various network environments.\n",
        "\n",
        "2.  Data Transformation Activities:\n",
        "These activities focus on transforming data into the required format, structure, or schema before loading it to the destination. Common tools and services for data transformation include Azure Databricks, SQL Stored Procedures, and Data Flow activities, which help modify and process the data accordingly.\n",
        "\n",
        "3. Control Flow Activities:\n",
        "Control flow activities manage the execution and orchestration of other activities within the pipeline. They enable workflow logic, such as conditional execution, iteration, and error handling. This ensures that the pipeline runs smoothly based on specified conditions and order of execution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Large-scale data processing with Azure Data Lake Storage Gen2\n",
        "### Introduction to Azure Data Lake Storage Gen2\n",
        "#### Understand Azure Data Lake Storage Gen2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which format is data stored in in a data lake?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Data in a data lake is usually stored in its original form without being processed or structured beforehand. This means it can include raw, unstructured, semi-structured, or structured data. Common formats used for storage include CSV, JSON, Parquet, ORC, and Avro, which allow flexibility for different analytics and processing needs. Since Azure Data Lake Storage Gen2 is optimized for big data, it supports Hadoop-compatible file formats like Parquet, which is highly compressed and efficient for analytical workloads. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which factors should influence the planning of a data lake?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: When planning a data lake, several key factors must be considered:\n",
        "\n",
        "When planning a data lake, several factors must be considered to ensure efficiency and usability:\n",
        "\n",
        "1.Data Organization – Structuring folders and files logically to optimize storage and retrieval.\n",
        "\n",
        "2.Storage Format – Choosing efficient formats like Parquet or ORC for better performance and reduced storage costs.\n",
        "\n",
        "3.Security & Access Control – Implementing RBAC (Role-Based Access Control), encryption, and compliance policies to protect sensitive data.\n",
        "\n",
        "4.Scalability & Performance – Ensuring the data lake can handle increasing data volumes while maintaining high-speed read/write operations.\n",
        "\n",
        "5.Integration with Analytics Tools – Ensuring compatibility with Azure Synapse Analytics, Databricks, Power BI, and other big data tools.\n",
        "\n",
        "6.Data Lifecycle Management – Defining retention, archival, and deletion policies to manage costs and ensure compliance.\n",
        "\n",
        "By addressing these factors, organizations can create a well-structured, cost-efficient, and high-performing data lake environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Enable Azure Data Lake storage Gen2 in Azure Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the name of the option that enables Azure Data Lake Storage Gen2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: To enable Azure Data Lake Storage Gen2, we must activate the \"Hierarchical Namespace\" feature when creating a storage account. This option enhances the storage system by allowing file and directory-level operations, enabling efficient data management similar to a traditional file system. The hierarchical namespace is essential for improving query performance, security, and file-level access control within the data lake.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compare Azure Data Lake Storage and Azure Blob storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the main difference between Azure Data Lake Storage and Azure Blob storage?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: The main difference between Azure Data Lake Storage Gen2 (ADLS Gen2) and Azure Blob Storage lies in their architecture and intended use cases:\n",
        "\n",
        "a.Azure Blob Storage is an object storage system optimized for storing unstructured data like images, videos, and backups. It has a flat namespace, which means it does not support file-level hierarchy efficiently.\n",
        "\n",
        "b.Azure Data Lake Storage Gen2 (ADLS Gen2) extends Blob Storage but introduces a Hierarchical Namespace, allowing for directory-based operations that improve performance when handling big data analytics workloads.\n",
        "\n",
        "If the goal is simple storage and retrieval, Azure Blob Storage is the better choice. If the objective is big data analytics and large-scale data processing, Azure Data Lake Storage Gen2 is the recommended solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of storage account should you use to store website assets such as images and videos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Azure Blob Storage is the best choice for storing website assets like images and videos because it is designed for scalable and efficient object storage. It integrates well with content delivery networks (CDNs) to ensure fast loading times, making it ideal for web applications that need to serve media files globally. Additionally, it allows flexible access control, enabling both public and private storage options based on security needs. With different pricing tiers such as Hot, Cool, and Archive, it provides cost-effective storage solutions. Unlike Azure Data Lake Storage Gen2, which is optimized for big data analytics, Azure Blob Storage is specifically built for storing and delivering static content efficiently.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of storage account should you use to store data that you wih to perform analytics on?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: For analytical workloads, Azure Data Lake Storage Gen2 is the recommended storage solution. It is optimized for big data processing and integrates seamlessly with Azure Synapse Analytics, Databricks, and machine learning platforms. The Hierarchical Namespace feature enables efficient file operations, making it ideal for storing large datasets for AI, Azure Machine Learning, and business intelligence applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use Azure Data Lake Storage Gen2 in data analytics workloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What are the three \"v's\" that are involved when processing big data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: When dealing with big data, three key factors—often referred to as the three V’s—must be considered:\n",
        "\n",
        "1.Volume – The sheer amount of data being generated and stored. Modern enterprises collect petabytes of structured and unstructured data from multiple sources, requiring scalable storage solutions like Azure Data Lake Storage.\n",
        "\n",
        "2.Velocity – The speed at which data is generated, processed, and analyzed. Real-time analytics, IoT data streams, and high-frequency transactions require low-latency processing solutions such as Azure Stream Analytics and Azure Databricks.\n",
        "\n",
        "3.Variety – The different types of data that organizations handle, including structured (databases), semi-structured (JSON, XML), and unstructured (videos, images, logs). Azure Data Lake Storage supports all these formats, making it a versatile option for complex data processing needs.\n",
        "\n",
        "Understanding these three V’s helps organizations implement efficient data processing strategies that balance storage, speed, and diversity for modern analytics applications.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "/home/linus/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
